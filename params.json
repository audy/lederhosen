{"name":"Lederhosen","tagline":"Turn 16S rRNA sequences into usable data","body":"<img src=\"https://raw.github.com/audy/lederhosen/master/logo.png\" align=\"right\">\r\n\r\n# Lederhosen\r\n\r\nLederhosen is a set of tools for OTU clustering rRNA amplicons using\r\nRobert Edgar's USEARCH and is simple, robust, and fast.\r\nLederhosen was designed from the beginning to handle lots of data from\r\nlots of samples, specifically from data generated by multiplexed\r\nIllumina Hi/Mi-Seq sequencing.\r\n\r\nNo assumptions are made about the design of your experiment.\r\nTherefore, there are no tools for read pre-processing and data analysis\r\nor statistics. Insert reads, receive data.\r\n\r\n### About\r\n\r\n- Lederhosen is designed to be a fast and **simple** (~700 SLOC) tool to aid in clustering 16S rRNA amplicons sequenced\r\nusing paired and non-paired end short reads such as those produced by Illumina (GAIIx, HiSeq and MiSeq), Ion Torrent, or Roche-454.\r\n- Lederhosen uses [Semantic Versioning](http://semver.org/), is free and open source under the\r\n[MIT open source license](http://opensource.org/licenses/mit-license.php/).\r\n- Except for USEARCH which requires a license, Lederhosen is available for commercial use.\r\n\r\n### Features\r\n\r\n- Referenced-based OTU clustering to via USEARCH.\r\n- Multiple Database Support (RDP, GreenGenes, TaxCollector, Silva).\r\n- Parallel support (USEARCH, MapReduce or Compute Cluster).\r\n- Generation and filtering of OTU abundancy matrices.\r\n\r\n### Installation\r\n\r\n0. Obtain & Install [USEARCH](http://www.drive5.com/).\r\n1. Get a database:\r\n  - [TaxCollector](http://github.com/audy/taxcollector)\r\n  - [GreenGenes](http://greengenes.lbl.gov) 16S database\r\n  - File an [issue report](https://github.com/audy/lederhosen/issues) or pull request ;) to request support for a different database.\r\n2. Install Lederhosen by typing:\r\n\r\n    `sudo gem install lederhosen`\r\n4. Check installation by typing `lederhosen`. You should see some help text.\r\n\r\n### Need Help?\r\n\r\nBug me: [@heyaudy](http://twitter.com/heyaudy) (twitter)\r\n\r\n## Tasks\r\n\r\nLederhosen is invoked by typing `lederhosen [TASK]`\r\n\r\n### Trim Reads\r\n\r\nTrimming removed. I think you should use\r\n[Sickle](https://github.com/najoshi/sickle), or\r\n[Trimmomatic](http://www.usadellab.org/cms/index.php?page=trimmomatic).\r\nYou can use\r\n[FastQC](http://www.bioinformatics.babraham.ac.uk/projects/fastqc/) to inspect read quality.\r\n\r\n### Create Database\r\n\r\nCreate UDB database required by usearch from TaxCollector\r\n\r\n```bash\r\nlederhosen make_udb \\\r\n  --input=taxcollector.fa \\\r\n  --output=taxcollector.udb\r\n```\r\n\r\n(not actually required but will make batch searching a lot faster)\r\n\r\n### Cluster Reads using USEARCH\r\n\r\nCluster reads using USEARCH. Output is a uc file.\r\n\r\n```bash\r\nlederhosen cluster \\\r\n  --input=trimmed/sequences.fasta \\\r\n  --identity=0.95 \\\r\n  --output=clusters_95.uc \\\r\n  --database=taxcollector.udb\r\n```\r\n\r\nThe optional `--dry-run` parameter outputs the usearch command to standard out.\r\nThis is useful if you want to run usearch on a cluster.\r\n\r\n```bash\r\nfor reads_file in reads/*.fasta;\r\ndo\r\n    echo lederhosen cluster \\\r\n                    --input=$reads_file \\\r\n                    --identity=0.95 \\\r\n                    --output=$(basename $reads_file_ .fasta).95.uc \\\r\n                    --database=taxcollector.udb \\\r\n                    --threads 1 \\\r\n                    --dry-run\r\nend > jobs.sh\r\n\r\n# send jobs to queue system\r\ncat jobs.sh | parallel -j 24 # run 24 parallel jobs\r\n```\r\n\r\n### Generate taxonomy counts tables\r\n\r\nBefore generating OTU tables, you must generate taxonomy counts tables.\r\n\r\nA taxonomy count table looks something like this\r\n\r\n    # taxonomy, number_of_reads\r\n    [0]Bacteria[1];...;[8]Akkermansia_municipalia, 28\r\n    ...\r\n\r\nFrom there, you can generate OTU abundance matrices at the different levels of classification (domain, phylum, ..., genus, species).\r\n\r\n```bash\r\n\r\nlederhosen count_taxonomies \\\r\n  --input=clusters.uc \\\r\n  --output=clusters_taxonomies.txt\r\n```\r\n\r\nIf you did paired-end sequencing, you can generate strict taxonomy tables that only count reads when *both pairs* have the *same*\r\ntaxonomic description at a certain taxonomic level. This is useful for leveraging the increased length of having pairs and also\r\nacts as a sort of chimera filter. You will, however, end up using less of your reads as the level goes from domain to species.\r\n\r\n```bash\r\nlederhosen count_taxonomies \\\r\n  --input=clusters.uc \\\r\n  --strict=genus \\\r\n  --output=clusters_taxonomies.strict.genus.txt\r\n```\r\n\r\nReads that do not have the same phylogeny at `level` will become `unclassified_reads`\r\n\r\n### Generate OTU tables\r\n\r\nCreate an OTU abundance table where rows are samples and columns are clusters. The entries are the number of reads for that cluster in a sample.\r\n\r\n```bash\r\nlederhosen otu_table \\\r\n  --files=clusters_taxonomies.strict.genus.*.txt \\\r\n  --output=my_poop_samples_genus_strict.95.txt \\\r\n  --level=genus\r\n```\r\n\r\nThis will create the file `my_poop_samples_genus_strict.95.txt` containing the clusters\r\nas columns and the samples as rows.\r\n\r\nYou now will apply advanced data mining and statistical techniques to this table to make\r\ninteresting biological inferences and cure diseases.\r\n\r\n### Filter OTU tables\r\n\r\nSometimes, clustering high-throughput reads at stringent identities can create many, small clusters.\r\nIn fact, these clusters represent the vast majority (>99%) of the created clusters but the minority (<1%>)\r\nof the reads. In other words, 1% of the reads have 99% of the clusters.\r\n\r\nIf you want to filter out these small clusters which are composed of inseparable sequencing error or\r\nactual biodiversity, you can do so with the `otu_filter` task.\r\n\r\n```bash\r\nlederhosen otu_filter \\\r\n  --input=table.csv \\\r\n  --output=filtere.csv \\\r\n  --reads=50 \\\r\n  --samples=50\r\n```\r\n\r\nThis will remove any clusters that do not appear in at least 10 samples with at least 50 reads. The read counts\r\nfor filtered clusters will be moved to the `noise` psuedocluster.\r\n\r\n\r\n### Get representative sequences\r\n\r\nYou can get the representative sequences for each cluster using the `get_reps` tasks.\r\nThis will extract the representative sequence from the __database__ you ran usearch with.\r\nMake sure you use the same database that you used when running usearch.\r\n\r\n```bash\r\nlederhosen get_reps \\\r\n  --input=clusters.uc \\\r\n  --database=taxcollector.fa \\\r\n  --output=representatives.fasta\r\n```\r\n\r\nYou can get the representatives from more than one cluster file using a glob:\r\n\r\n```bash\r\nlederhosen get_reps \\\r\n  --input=*.uc \\\r\n  --database=taxcollector.fa \\\r\n  --output=representatives.fasta\r\n```\r\n\r\n### Get unclassified sequences\r\n\r\n```bash\r\nlederhosen separate_unclassified \\\r\n  --uc-file=my_results.uc \\\r\n  --reads=reads_that_were_used_to_generate_results.fasta\r\n  --output=unclassified_reads.fasta\r\n```\r\n\r\n`separate_unclassified` has support for strict pairing\r\n\r\n```\r\nlederhosen separate_unclassified \\\r\n  --uc-file=my_results.uc \\\r\n  --reads=reads_that_were_used_to_generate_results.fasta\r\n  --strict=phylum\r\n  --output=unclassified_reads.fasta\r\n```\r\n\r\n## Acknowledgements\r\n\r\n- Lexi, Vinnie and Kevin for beta-testing and putting up with bugs\r\n- The QIIME project for inspiration\r\n- Sinbad Richardson for the Lederhosen Guy artwork\r\n\r\n## Please Cite\r\n\r\nPlease cite this GitHub repo (https://github.com/audy/lederhosen) with the version you used (type `lederhosen version`) unless I publish a paper. Then cite that.\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}